# 项目实战1：网络爬虫余爬取股票数据
## 网络爬虫基数概述
### 网络通信技术
### 多线程技术
### 数据交换技术
### web前端技术
### 数据存储技术
## 爬取数据
### 网页中静态和动态数据
### 使用urllib爬取数据
1. 获得静态数据


```python
import urllib.request


url = "file:///C:/Users/HP/nasdaq-Apple1.html"
req = urllib.request.Request(url)

with urllib.request.urlopen(req) as response:
    data = response.read()
    htmlstr = data.decode()
    print(htmlstr)
```


```python
<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="Generator" content="EditPlus®">
    <meta name="Author" content="">
    <meta name="Keywords" content="">
    <meta name="Description" content="">
    <title>Document</title>
</head>
<body>
<div id="quotes_content_left_pnlAJAX">
    <table class="historical-data__table">
        <thead class="historical-data__table-headings">
        <tr class="historical-data__row historical-data__row--headings">
            <th class="historical-data__table-heading" scope="col">Date</th>
            <th class="historical-data__table-heading" scope="col">Open</th>
            <th class="historical-data__table-heading" scope="col">High</th>
            <th class="historical-data__table-heading" scope="col">Low</th>
            <th class="historical-data__table-heading" scope="col">Close/Last</th>
            <th class="historical-data__table-heading" scope="col">Volume</th>
        </tr>
        </thead>
        <tbody class="historical-data__table-body">
        <tr class="historical-data__row">
            <th>10/04/2019</th>
            <td>225.64</td>
            <td>227.49</td>
            <td>223.89</td>
            <td>227.01</td>
            <td>34,755,550</td>
        </tr>
        <tr class="historical-data__row">
            <th>10/03/2019</th>
            <td>218.43</td>
            <td>220.96</td>
            <td>215.132</td>
            <td>220.82</td>
            <td>30,352,690</td>
        </tr>
        <tr class="historical-data__row">
            <th>10/02/2019</th>
            <td>223.06</td>
            <td>223.58</td>
            <td>217.93</td>
            <td>218.96</td>
            <td>35,767,260</td>
        </tr>
        <tr class="historical-data__row">
            <th>10/01/2019</th>
            <td>225.07</td>
            <td>228.22</td>
            <td>224.2</td>
            <td>224.59</td>
            <td>36,187,160</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/30/2019</th>
            <td>220.9</td>
            <td>224.58</td>
            <td>220.79</td>
            <td>223.97</td>
            <td>26,318,580</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/27/2019</th>
            <td>220.54</td>
            <td>220.96</td>
            <td>217.2814</td>
            <td>218.82</td>
            <td>25,361,290</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/26/2019</th>
            <td>220</td>
            <td>220.94</td>
            <td>218.83</td>
            <td>219.89</td>
            <td>19,088,310</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/25/2019</th>
            <td>218.55</td>
            <td>221.5</td>
            <td>217.1402</td>
            <td>221.03</td>
            <td>22,481,010</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/24/2019</th>
            <td>221.03</td>
            <td>222.49</td>
            <td>217.19</td>
            <td>217.68</td>
            <td>31,434,370</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/23/2019</th>
            <td>218.95</td>
            <td>219.84</td>
            <td>217.65</td>
            <td>218.72</td>
            <td>19,419,650</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/20/2019</th>
            <td>221.38</td>
            <td>222.56</td>
            <td>217.473</td>
            <td>217.73</td>
            <td>57,977,090</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/19/2019</th>
            <td>222.01</td>
            <td>223.76</td>
            <td>220.37</td>
            <td>220.96</td>
            <td>22,187,880</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/18/2019</th>
            <td>221.06</td>
            <td>222.85</td>
            <td>219.44</td>
            <td>222.77</td>
            <td>25,643,090</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/17/2019</th>
            <td>219.96</td>
            <td>220.82</td>
            <td>219.12</td>
            <td>220.7</td>
            <td>18,386,470</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/16/2019</th>
            <td>217.73</td>
            <td>220.13</td>
            <td>217.56</td>
            <td>219.9</td>
            <td>21,158,140</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/13/2019</th>
            <td>220</td>
            <td>220.79</td>
            <td>217.02</td>
            <td>218.75</td>
            <td>39,763,300</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/12/2019</th>
            <td>224.8</td>
            <td>226.42</td>
            <td>222.86</td>
            <td>223.085</td>
            <td>32,226,670</td>
        </tr>
        <tr class="historical-data__row">
            <th>09/11/2019</th>
            <td>218.07</td>
            <td>223.71</td>
            <td>217.73</td>
            <td>223.59</td>
            <td>44,289,650</td>
        </tr>
        </tbody>
    </table>
</div>
</body>
</html>
```

2. 获得动态数据


```python
import re
import urllib.request

url = 'http://q.stock.sohu.com/hisHq?code=cn_600519&stat=1&order=D&period=d&callback=historySearchHandler&rt=jsonp&0.8115656498417958'
req = urllib.request.Request(url)

with urllib.request.urlopen(req) as response:
    data = response.read()
    htmlstr = data.decode('gbk')
    print(htmlstr)
    htmlstr = htmlstr.replace('historySearchHandler(', '')
    htmlstr = htmlstr.replace(')', '')
    print('替换后的：', htmlstr)
```


```python
historySearchHandler([{"status":0,"hq":[["2023-04-18","1753.00","1758.00","5.00","0.29%","1746.02","1769.00","18314","322010.75","0.15%"],["2023-04-17","1740.00","1753.00","39.58","2.31%","1728.00","1753.00","30467","530340.12","0.24%"],["2023-04-14","1726.00","1713.42","-9.58","-0.56%","1704.80","1733.00","21232","364652.69","0.17%"],["2023-04-13","1690.00","1723.00","28.90","1.71%","1684.01","1723.59","29543","504931.03","0.24%"],["2023-04-12","1747.26","1694.10","-51.40","-2.94%","1692.82","1750.00","51105","873265.75","0.41%"],["2023-04-11","1793.00","1745.50","-26.20","-1.48%","1744.00","1793.00","29209","513885.44","0.23%"],["2023-04-10","1790.88","1771.70","-19.29","-1.08%","1744.00","1790.88","29418","517115.03","0.23%"],["2023-04-07","1795.00","1790.99","-5.97","-0.33%","1788.34","1806.01","13525","242816.05","0.11%"],["2023-04-06","1805.00","1796.96","-17.63","-0.97%","1788.22","1815.90","14874","267625.19","0.12%"],["2023-04-04","1812.00","1814.59","12.52","0.69%","1787.00","1815.17","20066","361427.53","0.16%"],["2023-04-03","1825.00","1802.07","-17.93","-0.99%","1800.08","1827.77","21417","387581.16","0.17%"],["2023-03-31","1825.00","1820.00","20.00","1.11%","1819.00","1848.00","27446","502479.06","0.22%"],["2023-03-30","1793.00","1800.00","10.00","0.56%","1779.00","1805.00","19257","345357.31","0.15%"],["2023-03-29","1799.00","1790.00","8.20","0.46%","1785.07","1800.00","15393","276190.94","0.12%"],["2023-03-28","1770.00","1781.80","14.01","0.79%","1765.02","1790.00","17261","307311.31","0.14%"],["2023-03-27","1778.60","1767.79","-10.83","-0.61%","1756.00","1778.60","15296","270075.59","0.12%"],["2023-03-24","1769.08","1778.62","3.76","0.21%","1766.00","1783.60","12770","226964.92","0.10%"],["2023-03-23","1766.00","1774.86","1.51","0.09%","1765.01","1791.11","17356","308282.16","0.14%"],["2023-03-22","1780.00","1773.35","-1.65","-0.09%","1765.55","1793.00","15330","272764.88","0.12%"],["2023-03-21","1735.00","1775.00","45.40","2.62%","1723.97","1785.85","31142","549105.19","0.25%"],["2023-03-20","1751.00","1729.60","-12.40","-0.71%","1728.00","1755.00","20491","355787.22","0.16%"],["2023-03-17","1770.00","1742.00","-9.99","-0.57%","1736.00","1775.89","27023","474424.94","0.22%"],["2023-03-16","1740.00","1751.99","1.07","0.06%","1739.01","1770.00","17646","309679.09","0.14%"],["2023-03-15","1778.37","1750.92","-15.08","-0.85%","1750.12","1784.88","19213","339269.84","0.15%"],["2023-03-14","1763.78","1766.00","4.00","0.23%","1738.50","1779.88","23705","417728.91","0.19%"],["2023-03-13","1751.00","1762.00","12.00","0.69%","1749.00","1775.00","20560","362647.62","0.16%"],["2023-03-10","1751.57","1750.00","-20.02","-1.13%","1750.00","1781.00","21161","372513.91","0.17%"],["2023-03-09","1768.00","1770.02","-0.40","-0.02%","1740.00","1785.00","27612","488144.28","0.22%"],["2023-03-08","1780.02","1770.42","-17.88","-1.00%","1761.12","1785.94","22764","403578.72","0.18%"],["2023-03-07","1805.98","1788.30","-18.84","-1.04%","1788.00","1816.60","22785","410130.25","0.18%"],["2023-03-06","1818.18","1807.14","-10.90","-0.60%","1796.77","1818.50","20646","373007.94","0.16%"],["2023-03-03","1839.77","1818.04","-9.96","-0.54%","1802.48","1841.61","16198","294684.25","0.13%"],["2023-03-02","1829.00","1828.00","-10.53","-0.57%","1821.10","1838.99","13144","240529.23","0.10%"],["2023-03-01","1813.00","1838.53","24.79","1.37%","1803.23","1848.00","24458","447559.22","0.19%"],["2023-02-28","1819.00","1813.74","3.33","0.18%","1783.30","1822.01","23952","431487.69","0.19%"],["2023-02-27","1778.50","1810.41","22.41","1.25%","1775.02","1815.00","22065","397812.88","0.18%"],["2023-02-24","1810.11","1788.00","-30.00","-1.65%","1782.18","1810.19","24635","441562.16","0.20%"],["2023-02-23","1840.00","1818.00","-18.00","-0.98%","1805.25","1848.80","21881","398399.12","0.17%"],["2023-02-22","1855.01","1836.00","-31.00","-1.66%","1831.80","1863.90","21869","403101.59","0.17%"],["2023-02-21","1874.00","1867.00","-8.00","-0.43%","1851.00","1874.00","18751","349163.34","0.15%"],["2023-02-20","1821.00","1875.00","54.22","2.98%","1817.20","1878.80","29669","548880.00","0.24%"],["2023-02-17","1850.16","1820.78","-41.04","-2.20%","1820.05","1873.00","26443","488032.88","0.21%"],["2023-02-16","1841.34","1861.82","20.82","1.13%","1828.00","1887.00","33246","619691.50","0.26%"],["2023-02-15","1843.78","1841.00","-2.79","-0.15%","1835.81","1855.30","18177","335142.22","0.14%"],["2023-02-14","1856.46","1843.79","-12.56","-0.68%","1835.00","1857.40","19566","360176.94","0.16%"],["2023-02-13","1810.00","1856.35","46.35","2.56%","1810.00","1874.50","38147","705838.25","0.30%"],["2023-02-10","1810.10","1810.00","-8.00","-0.44%","1801.05","1818.49","17985","325385.94","0.14%"],["2023-02-09","1778.00","1818.00","34.00","1.91%","1775.01","1829.75","29754","540139.94","0.24%"],["2023-02-08","1800.01","1784.00","-13.00","-0.72%","1775.00","1805.97","16676","298057.47","0.13%"],["2023-02-07","1808.08","1797.00","2.00","0.11%","1787.73","1808.80","24322","437367.19","0.19%"],["2023-02-06","1780.00","1795.00","-23.00","-1.27%","1760.00","1795.00","42661","759573.94","0.34%"],["2023-02-03","1820.00","1818.00","-18.11","-0.99%","1795.68","1826.00","34945","632463.50","0.28%"],["2023-02-02","1848.38","1836.11","-8.86","-0.48%","1826.00","1859.00","29759","546550.94","0.24%"],["2023-02-01","1854.98","1844.97","-0.79","-0.04%","1811.40","1859.00","33974","624467.94","0.27%"],["2023-01-31","1896.50","1845.76","-42.24","-2.24%","1833.07","1899.95","32991","612831.12","0.26%"],["2023-01-30","1909.00","1888.00","27.99","1.50%","1880.00","1909.00","35923","679975.69","0.29%"],["2023-01-20","1889.19","1860.01","-20.20","-1.07%","1858.00","1898.25","25609","480735.59","0.20%"],["2023-01-19","1892.50","1880.21","-12.79","-0.68%","1866.00","1892.52","23439","440199.44","0.19%"],["2023-01-18","1914.00","1893.00","-15.00","-0.79%","1890.00","1925.30","21063","400866.53","0.17%"],["2023-01-17","1913.16","1908.00","-4.90","-0.26%","1895.00","1923.00","21299","406832.16","0.17%"],["2023-01-16","1886.00","1912.90","25.90","1.37%","1881.00","1935.00","36848","705998.31","0.29%"],["2023-01-13","1844.18","1887.00","53.00","2.89%","1840.00","1888.00","31940","596987.62","0.25%"],["2023-01-12","1848.00","1834.00","-10.95","-0.59%","1833.00","1856.00","17193","316263.72","0.14%"],["2023-01-11","1856.00","1844.95","-9.50","-0.51%","1836.84","1860.00","22720","420148.78","0.18%"],["2023-01-10","1839.06","1854.45","13.25","0.72%","1830.50","1864.50","22732","420478.38","0.18%"],["2023-01-09","1835.00","1841.20","37.43","2.08%","1807.82","1849.98","30977","568418.12","0.25%"],["2023-01-06","1806.12","1803.77","2.77","0.15%","1787.00","1811.90","24904","448083.88","0.20%"],["2023-01-05","1737.00","1801.00","75.99","4.41%","1733.00","1801.00","47943","854158.69","0.38%"],["2023-01-04","1730.00","1725.01","-5.00","-0.29%","1716.00","1738.70","20416","352358.22","0.16%"],["2023-01-03","1731.20","1730.01","3.01","0.17%","1706.01","1738.43","26034","448776.03","0.21%"],["2022-12-30","1736.00","1727.00","8.00","0.47%","1727.00","1752.99","25333","440954.41","0.20%"],["2022-12-29","1717.00","1719.00","-14.00","-0.81%","1701.05","1726.99","22418","384449.97","0.18%"],["2022-12-28","1745.88","1733.00","0.00","0.00%","1708.01","1747.00","21438","369994.91","0.17%"],["2022-12-27","1738.00","1733.00","12.85","0.75%","1725.50","1747.15","17905","310927.03","0.14%"],["2022-12-26","1771.00","1742.06","-28.94","-1.63%","1735.02","1771.00","21384","374912.09","0.17%"],["2022-12-23","1752.40","1771.00","3.00","0.17%","1745.00","1782.00","17319","306360.84","0.14%"],["2022-12-22","1756.70","1768.00","29.00","1.67%","1745.00","1783.00","23175","409386.16","0.18%"],["2022-12-21","1724.00","1739.00","24.00","1.40%","1717.65","1739.00","22816","394892.62","0.18%"],["2022-12-20","1765.33","1715.00","-58.00","-3.27%","1682.45","1765.33","46198","794412.06","0.37%"],["2022-12-19","1798.80","1773.00","-13.87","-0.78%","1760.17","1798.80","24987","444723.66","0.20%"]],"code":"cn_600519","stat":["累计:","2022-12-19至2023-04-18","-28.87","-1.62%",1682.45,1935,1961308,35261288.98,"15.59%"]}])

替换后的： [{"status":0,"hq":[["2023-04-18","1753.00","1758.00","5.00","0.29%","1746.02","1769.00","18314","322010.75","0.15%"],["2023-04-17","1740.00","1753.00","39.58","2.31%","1728.00","1753.00","30467","530340.12","0.24%"],["2023-04-14","1726.00","1713.42","-9.58","-0.56%","1704.80","1733.00","21232","364652.69","0.17%"],["2023-04-13","1690.00","1723.00","28.90","1.71%","1684.01","1723.59","29543","504931.03","0.24%"],["2023-04-12","1747.26","1694.10","-51.40","-2.94%","1692.82","1750.00","51105","873265.75","0.41%"],["2023-04-11","1793.00","1745.50","-26.20","-1.48%","1744.00","1793.00","29209","513885.44","0.23%"],["2023-04-10","1790.88","1771.70","-19.29","-1.08%","1744.00","1790.88","29418","517115.03","0.23%"],["2023-04-07","1795.00","1790.99","-5.97","-0.33%","1788.34","1806.01","13525","242816.05","0.11%"],["2023-04-06","1805.00","1796.96","-17.63","-0.97%","1788.22","1815.90","14874","267625.19","0.12%"],["2023-04-04","1812.00","1814.59","12.52","0.69%","1787.00","1815.17","20066","361427.53","0.16%"],["2023-04-03","1825.00","1802.07","-17.93","-0.99%","1800.08","1827.77","21417","387581.16","0.17%"],["2023-03-31","1825.00","1820.00","20.00","1.11%","1819.00","1848.00","27446","502479.06","0.22%"],["2023-03-30","1793.00","1800.00","10.00","0.56%","1779.00","1805.00","19257","345357.31","0.15%"],["2023-03-29","1799.00","1790.00","8.20","0.46%","1785.07","1800.00","15393","276190.94","0.12%"],["2023-03-28","1770.00","1781.80","14.01","0.79%","1765.02","1790.00","17261","307311.31","0.14%"],["2023-03-27","1778.60","1767.79","-10.83","-0.61%","1756.00","1778.60","15296","270075.59","0.12%"],["2023-03-24","1769.08","1778.62","3.76","0.21%","1766.00","1783.60","12770","226964.92","0.10%"],["2023-03-23","1766.00","1774.86","1.51","0.09%","1765.01","1791.11","17356","308282.16","0.14%"],["2023-03-22","1780.00","1773.35","-1.65","-0.09%","1765.55","1793.00","15330","272764.88","0.12%"],["2023-03-21","1735.00","1775.00","45.40","2.62%","1723.97","1785.85","31142","549105.19","0.25%"],["2023-03-20","1751.00","1729.60","-12.40","-0.71%","1728.00","1755.00","20491","355787.22","0.16%"],["2023-03-17","1770.00","1742.00","-9.99","-0.57%","1736.00","1775.89","27023","474424.94","0.22%"],["2023-03-16","1740.00","1751.99","1.07","0.06%","1739.01","1770.00","17646","309679.09","0.14%"],["2023-03-15","1778.37","1750.92","-15.08","-0.85%","1750.12","1784.88","19213","339269.84","0.15%"],["2023-03-14","1763.78","1766.00","4.00","0.23%","1738.50","1779.88","23705","417728.91","0.19%"],["2023-03-13","1751.00","1762.00","12.00","0.69%","1749.00","1775.00","20560","362647.62","0.16%"],["2023-03-10","1751.57","1750.00","-20.02","-1.13%","1750.00","1781.00","21161","372513.91","0.17%"],["2023-03-09","1768.00","1770.02","-0.40","-0.02%","1740.00","1785.00","27612","488144.28","0.22%"],["2023-03-08","1780.02","1770.42","-17.88","-1.00%","1761.12","1785.94","22764","403578.72","0.18%"],["2023-03-07","1805.98","1788.30","-18.84","-1.04%","1788.00","1816.60","22785","410130.25","0.18%"],["2023-03-06","1818.18","1807.14","-10.90","-0.60%","1796.77","1818.50","20646","373007.94","0.16%"],["2023-03-03","1839.77","1818.04","-9.96","-0.54%","1802.48","1841.61","16198","294684.25","0.13%"],["2023-03-02","1829.00","1828.00","-10.53","-0.57%","1821.10","1838.99","13144","240529.23","0.10%"],["2023-03-01","1813.00","1838.53","24.79","1.37%","1803.23","1848.00","24458","447559.22","0.19%"],["2023-02-28","1819.00","1813.74","3.33","0.18%","1783.30","1822.01","23952","431487.69","0.19%"],["2023-02-27","1778.50","1810.41","22.41","1.25%","1775.02","1815.00","22065","397812.88","0.18%"],["2023-02-24","1810.11","1788.00","-30.00","-1.65%","1782.18","1810.19","24635","441562.16","0.20%"],["2023-02-23","1840.00","1818.00","-18.00","-0.98%","1805.25","1848.80","21881","398399.12","0.17%"],["2023-02-22","1855.01","1836.00","-31.00","-1.66%","1831.80","1863.90","21869","403101.59","0.17%"],["2023-02-21","1874.00","1867.00","-8.00","-0.43%","1851.00","1874.00","18751","349163.34","0.15%"],["2023-02-20","1821.00","1875.00","54.22","2.98%","1817.20","1878.80","29669","548880.00","0.24%"],["2023-02-17","1850.16","1820.78","-41.04","-2.20%","1820.05","1873.00","26443","488032.88","0.21%"],["2023-02-16","1841.34","1861.82","20.82","1.13%","1828.00","1887.00","33246","619691.50","0.26%"],["2023-02-15","1843.78","1841.00","-2.79","-0.15%","1835.81","1855.30","18177","335142.22","0.14%"],["2023-02-14","1856.46","1843.79","-12.56","-0.68%","1835.00","1857.40","19566","360176.94","0.16%"],["2023-02-13","1810.00","1856.35","46.35","2.56%","1810.00","1874.50","38147","705838.25","0.30%"],["2023-02-10","1810.10","1810.00","-8.00","-0.44%","1801.05","1818.49","17985","325385.94","0.14%"],["2023-02-09","1778.00","1818.00","34.00","1.91%","1775.01","1829.75","29754","540139.94","0.24%"],["2023-02-08","1800.01","1784.00","-13.00","-0.72%","1775.00","1805.97","16676","298057.47","0.13%"],["2023-02-07","1808.08","1797.00","2.00","0.11%","1787.73","1808.80","24322","437367.19","0.19%"],["2023-02-06","1780.00","1795.00","-23.00","-1.27%","1760.00","1795.00","42661","759573.94","0.34%"],["2023-02-03","1820.00","1818.00","-18.11","-0.99%","1795.68","1826.00","34945","632463.50","0.28%"],["2023-02-02","1848.38","1836.11","-8.86","-0.48%","1826.00","1859.00","29759","546550.94","0.24%"],["2023-02-01","1854.98","1844.97","-0.79","-0.04%","1811.40","1859.00","33974","624467.94","0.27%"],["2023-01-31","1896.50","1845.76","-42.24","-2.24%","1833.07","1899.95","32991","612831.12","0.26%"],["2023-01-30","1909.00","1888.00","27.99","1.50%","1880.00","1909.00","35923","679975.69","0.29%"],["2023-01-20","1889.19","1860.01","-20.20","-1.07%","1858.00","1898.25","25609","480735.59","0.20%"],["2023-01-19","1892.50","1880.21","-12.79","-0.68%","1866.00","1892.52","23439","440199.44","0.19%"],["2023-01-18","1914.00","1893.00","-15.00","-0.79%","1890.00","1925.30","21063","400866.53","0.17%"],["2023-01-17","1913.16","1908.00","-4.90","-0.26%","1895.00","1923.00","21299","406832.16","0.17%"],["2023-01-16","1886.00","1912.90","25.90","1.37%","1881.00","1935.00","36848","705998.31","0.29%"],["2023-01-13","1844.18","1887.00","53.00","2.89%","1840.00","1888.00","31940","596987.62","0.25%"],["2023-01-12","1848.00","1834.00","-10.95","-0.59%","1833.00","1856.00","17193","316263.72","0.14%"],["2023-01-11","1856.00","1844.95","-9.50","-0.51%","1836.84","1860.00","22720","420148.78","0.18%"],["2023-01-10","1839.06","1854.45","13.25","0.72%","1830.50","1864.50","22732","420478.38","0.18%"],["2023-01-09","1835.00","1841.20","37.43","2.08%","1807.82","1849.98","30977","568418.12","0.25%"],["2023-01-06","1806.12","1803.77","2.77","0.15%","1787.00","1811.90","24904","448083.88","0.20%"],["2023-01-05","1737.00","1801.00","75.99","4.41%","1733.00","1801.00","47943","854158.69","0.38%"],["2023-01-04","1730.00","1725.01","-5.00","-0.29%","1716.00","1738.70","20416","352358.22","0.16%"],["2023-01-03","1731.20","1730.01","3.01","0.17%","1706.01","1738.43","26034","448776.03","0.21%"],["2022-12-30","1736.00","1727.00","8.00","0.47%","1727.00","1752.99","25333","440954.41","0.20%"],["2022-12-29","1717.00","1719.00","-14.00","-0.81%","1701.05","1726.99","22418","384449.97","0.18%"],["2022-12-28","1745.88","1733.00","0.00","0.00%","1708.01","1747.00","21438","369994.91","0.17%"],["2022-12-27","1738.00","1733.00","12.85","0.75%","1725.50","1747.15","17905","310927.03","0.14%"],["2022-12-26","1771.00","1742.06","-28.94","-1.63%","1735.02","1771.00","21384","374912.09","0.17%"],["2022-12-23","1752.40","1771.00","3.00","0.17%","1745.00","1782.00","17319","306360.84","0.14%"],["2022-12-22","1756.70","1768.00","29.00","1.67%","1745.00","1783.00","23175","409386.16","0.18%"],["2022-12-21","1724.00","1739.00","24.00","1.40%","1717.65","1739.00","22816","394892.62","0.18%"],["2022-12-20","1765.33","1715.00","-58.00","-3.27%","1682.45","1765.33","46198","794412.06","0.37%"],["2022-12-19","1798.80","1773.00","-13.87","-0.78%","1760.17","1798.80","24987","444723.66","0.20%"]],"code":"cn_600519","stat":["累计:","2022-12-19至2023-04-18","-28.87","-1.62%",1682.45,1935,1961308,35261288.98,"15.59%"]}]
```

3. 伪装成浏览器


```python
import urllib.request


url = 'http://www.ctrip.com/'

req = urllib.request.Request(url)

req.add_header('User-Agent',
               'Mozilla/5.0 (iPhone; CPU iPhone OS 10_2_1 like Mac OS X) AppleWebKit/602.4.6 (KHTML, like Gecko) Version/10.0 Mobile/14D27 Safari/602.1')

with urllib.request.urlopen(req) as response:
    data = response.read()
    htmlstr = data.decode()
    if htmlstr.find('mobile') != -1:
        print('移动版')
```


```python
移动版
```

### 使用Selenium爬取数据


```python
from selenium import webdriver

driver = webdriver.Chrome()

driver.get('http://q.stock.sohu.com/cn/600519/lshq.shtml')
em = driver.find_element(By.id,'BIZ_hq_historySearch')
print(em.text)
# driver.close()
driver.quit()
```


    ---------------------------------------------------------------------------

    AttributeError                            Traceback (most recent call last)

    Input In [2], in <cell line: 6>()
          3 driver = webdriver.Chrome()
          5 driver.get('http://q.stock.sohu.com/cn/600519/lshq.shtml')
    ----> 6 em = driver.find_element_by_id('BIZ_hq_historySearch')
          7 print(em.text)
          8 # driver.close()
    

    AttributeError: 'WebDriver' object has no attribute 'find_element_by_id'


## 分析数据
### 使用正则表达式


```python
import urllib.request

import os
import re

url = 'http://p.weather.com.cn/'


def findallimageurl(htmlstr):
    """从HTML代码中查找匹配的字符串"""

    # 定义正则表达式
    pattern = r'http://\S+(?:\.png|\.jpg)'
    return re.findall(pattern, htmlstr)


def getfilename(urlstr):
    """根据图片连接地址截取图片名"""

    pos = urlstr.rfind('/')
    return urlstr[pos + 1:]


# 分析获得的url列表
url_list = []
req = urllib.request.Request(url)
with urllib.request.urlopen(req) as response:
    data = response.read()
    htmlstr = data.decode()

    url_list = findallimageurl(htmlstr)

for imagesrc in url_list:
    # 根据图片地址下载
    req = urllib.request.Request(imagesrc)
    with urllib.request.urlopen(req) as response:
        data = response.read()
        # 过滤掉用小于100kb字节的图片
        if len(data) < 1024 * 100:
            continue

        # 创建download文件夹
        if not os.path.exists('download'):
            os.mkdir('download')

        # 获得图片文件名
        filename = getfilename(imagesrc)
        filename = 'download/' + filename
        # 保存图片到本地
        with open(filename, 'wb') as f:
            f.write(data)

    print('下载图片', filename)
```

    下载图片 download/20230412105733E6869CA2C51FC9659543B01BCAD594C0.jpg
    下载图片 download/2023041210583373DC4BF4E9ABC5CC8C084D45FB133E3A.jpg
    下载图片 download/20230412105932202830A62B6E006C698504271BA9D52C.jpg
    下载图片 download/20230406160425985ECFF0D26CB2A423DAECD29141F4EE.jpg
    下载图片 download/20220401091431D32C5DA957F3441693885B05E271420C.jpg
    下载图片 download/2023041812043228512B6723F81BA42BC286530A7AD859.jpg
    下载图片 download/20230416152716215BBBA7CCF443222A245DA84B742444.jpg
    下载图片 download/202304160947448C2B8A7CF30225471547902BD50AB088.jpg
    下载图片 download/20230316141537671B47C5E4F520E11EE0E489187E624F.png
    

### 使用BeautifulSoup库


```python
import os
import urllib.request

from bs4 import BeautifulSoup

url = 'http://p.weather.com.cn/'


def findallimageurl(htmlstr):
    """从HTML代码中查找匹配的字符串"""

    sp = BeautifulSoup(htmlstr, 'html.parser') #html.parser html.parser
    # 返回所有的img标签对象
    imgtaglist = sp.find_all('img')

    # 从img标签对象列表中返回对应的src列表
    srclist = list(map(lambda u: u.get('src'), imgtaglist))
    # 过滤掉非.png和.jpg结尾文件src字符串
    filtered_srclist = filter(lambda u: u.lower().endswith('.png')
                                        or u.lower().endswith('.jpg'), srclist)

    return filtered_srclist


def getfilename(urlstr):
    """根据图片连接地址截取图片名"""

    pos = urlstr.rfind('/')
    return urlstr[pos + 1:]


# 分析获得的url列表
url_list = []
req = urllib.request.Request(url)
with urllib.request.urlopen(req) as response:
    data = response.read()
    htmlstr = data.decode()

    url_list = findallimageurl(htmlstr)

for imagesrc in url_list:
    # 根据图片地址下载
    req = urllib.request.Request(imagesrc)
    with urllib.request.urlopen(req) as response:
        data = response.read()
        # 过滤掉用小于100kb字节的图片
        if len(data) < 1024 * 100:
            continue

        # 创建download文件夹
        if not os.path.exists('download1'):
            os.mkdir('download1')

        # 获得图片文件名
        filename = getfilename(imagesrc)
        filename = 'download1/' + filename
        # 保存图片到本地
        with open(filename, 'wb') as f:
            f.write(data)

    print('下载图片', filename)
```

    下载图片 download1/20230412105733E6869CA2C51FC9659543B01BCAD594C0.jpg
    下载图片 download1/2023041210583373DC4BF4E9ABC5CC8C084D45FB133E3A.jpg
    下载图片 download1/20230412105932202830A62B6E006C698504271BA9D52C.jpg
    下载图片 download1/20230406160425985ECFF0D26CB2A423DAECD29141F4EE.jpg
    下载图片 download1/20220401091431D32C5DA957F3441693885B05E271420C.jpg
    下载图片 download1/2023041812043228512B6723F81BA42BC286530A7AD859.jpg
    下载图片 download1/20230416152716215BBBA7CCF443222A245DA84B742444.jpg
    下载图片 download1/202304160947448C2B8A7CF30225471547902BD50AB088.jpg
    下载图片 download1/20230316141537671B47C5E4F520E11EE0E489187E624F.png
    

## 爬取Nasdaq股票数据


```python

import datetime
import hashlib
import logging
import os
import re
import threading
import time
import urllib.request

from bs4 import BeautifulSoup

from db.db_access import insert_hisq_data





logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(threadName)s - '
                           '%(name)s - %(funcName)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# url = 'https://www.nasdaq.com/symbol/aapl/historical#.UWdnJBDMhHk'
# 换成自己到路径
url = 'file:///C:/Users/HP/nasdaq-Apple1.html'

def validateUpdate(html):
    """验证数据是否更新，更新返回True，未更新返回False"""

    # 创建md5对象
    md5obj = hashlib.md5()
    md5obj.update(html.encode(encoding='utf-8'))
    md5code = md5obj.hexdigest()

    old_md5code = ''
    f_name = 'md5.txt'

    if os.path.exists(f_name):  # 如果文件存在读取文件内容
        with open(f_name, 'r', encoding='utf-8') as f:
            old_md5code = f.read()

    if md5code == old_md5code:
        logger.info('数据没有更新')
        return False
    else:
        # 把新的md5码写入到文件中
        with open(f_name, 'w', encoding='utf-8') as f:
            f.write(md5code)
        logger.info('数据更新')
        return True


# 线程运行标志
isrunning = True
# 爬虫工作间隔
interval = 5


def controlthread_body():
    """控制线程体函数"""

    global interval, isrunning

    while isrunning:
        # 控制爬虫工作计划
        i = input('输入Bye终止爬虫，输入数字改变爬虫工作间隔，单位秒：')
        logger.info('控制输入{0}'.format(i))
        try:
            interval = int(i)
        except ValueError:
            if i.lower() == 'bye':
                isrunning = False


def istradtime():
    """判断交易时间"""

    now = datetime.datetime.now()
    df = '%H%M%S'
    strnow = now.strftime(df)
    starttime = datetime.time(hour=21, minute=30).strftime(df)
    endtime = datetime.time(hour=4, minute=0).strftime(df)

    if now.weekday() == 5 \
            or now.weekday() == 6 \
            or (endtime < strnow < starttime):
        # 非工作时间
        return False
    # 工作时间
    return True


def workthread_body():
    """工作线程体函数"""

    global interval, isrunning

    while isrunning:

        if istradtime():
            # 交易时间内不工作
            logger.info('交易时间，爬虫休眠1小时...')
            time.sleep(60 * 60)
            continue

        logger.info('爬虫开始工作...')
        req = urllib.request.Request(url)

        with urllib.request.urlopen(req) as response:
            data = response.read()
            html = data.decode()

            sp = BeautifulSoup(html, 'html.parser')
            # 返回指定CSS选择器的div标签列表
            div = sp.select('div#quotes_content_left_pnlAJAX')
            # 从列表中返回第一个元素
            divstring = div[0]

            if validateUpdate(divstring):  # 数据更新
                # 分析数据
                trlist = sp.select('div#quotes_content_left_pnlAJAX table tbody tr')

                data = []

                for tr in trlist:
                    trtext = tr.text.strip('\n\r ')
                    if trtext == '':
                        continue

                    rows = re.split(r'\s+', trtext)
                    fields = {}
                    try:
                        df = '%m/%d/%Y'
                        fields['Date'] = datetime.datetime.strptime(rows[0], df)
                    except ValueError:
                        # 实时数据不分析（只有时间，如10:12）
                        continue
                    fields['Open'] = float(rows[1])
                    fields['High'] = float(rows[2])
                    fields['Low'] = float(rows[3])
                    fields['Close'] = float(rows[4])
                    fields['Volume'] = int(rows[5].replace(',', ''))
                    data.append(fields)

                # 保存数据到数据库
                for row in data:
                    row['Symbol'] = 'AAPL'
                    insert_hisq_data(row)

            # 爬虫休眠
            logger.info('爬虫休眠{0}秒...'.format(interval))
            time.sleep(interval)


def main():
    """主函数"""

    global interval, isrunning
    # 创建工作线程对象workthread
    workthread = threading.Thread(target=workthread_body, name='WorkThread')
    # 启动线程workthread
    workthread.start()

    # 创建控制线程对象controlthread
    controlthread = threading.Thread(target=controlthread_body, name='ControlThread')
    # 启动线程controlthread
    controlthread.start()


if __name__ == '__main__':
    main()

```

    2023-04-19 15:46:27,709 - WorkThread - __main__ - workthread_body - INFO - 爬虫开始工作...
    2023-04-19 15:46:28,157 - WorkThread - __main__ - validateUpdate - INFO - 数据更新
    2023-04-19 15:46:28,236 - WorkThread - __main__ - workthread_body - INFO - 爬虫休眠5秒...
    2023-04-19 15:46:33,247 - WorkThread - __main__ - workthread_body - INFO - 爬虫开始工作...
    2023-04-19 15:46:33,255 - WorkThread - __main__ - validateUpdate - INFO - 数据没有更新
    2023-04-19 15:46:33,256 - WorkThread - __main__ - workthread_body - INFO - 爬虫休眠5秒...
    

    输入Bye终止爬虫，输入数字改变爬虫工作间隔，单位秒：3600
    

    2023-04-19 15:46:36,048 - ControlThread - __main__ - controlthread_body - INFO - 控制输入3600
    

    输入Bye终止爬虫，输入数字改变爬虫工作间隔，单位秒：

    Exception in thread ControlThread:
    Traceback (most recent call last):
      File "E:\anaconda\lib\threading.py", line 973, in _bootstrap_inner
        self.run()
      File "E:\anaconda\lib\threading.py", line 910, in run
        self._target(*self._args, **self._kwargs)
      File "C:\Users\HP\AppData\Local\Temp\ipykernel_22288\985097547.py", line 66, in controlthread_body
    EOFError: EOF when reading a line
    2023-04-19 15:46:38,259 - WorkThread - __main__ - workthread_body - INFO - 爬虫开始工作...
    2023-04-19 15:46:38,267 - WorkThread - __main__ - validateUpdate - INFO - 数据没有更新
    2023-04-19 15:46:38,267 - WorkThread - __main__ - workthread_body - INFO - 爬虫休眠3600秒...
    


```python

```
